{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNNTraining.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQBahpLV8sJo"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import glob\n",
        "import torch.nn as nn\n",
        "from torchvision.transforms import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "from torch.autograd import Variable\n",
        "import torchvision\n",
        "import pathlib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BREAqi3DJWL",
        "outputId": "6ea34fa1-62c7-4737-a0e2-bbd490ab7382"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ueyjyeejDZOu",
        "outputId": "70d88adc-538a-4108-8377-1e499ca79949"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYEP9Fd1DtVA"
      },
      "source": [
        "transformer = transforms.Compose([\n",
        "                                  transforms.RandomPerspective(distortion_scale=0.6,p=0.5), transforms.RandomRotation(degrees=(0,180)),\n",
        "                                  transforms.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75)), transforms.RandomInvert(p=0.2),\n",
        "                                  transforms.RandomAdjustSharpness(0, p=0.25), transforms.RandomAdjustSharpness(2, p=0.25),\n",
        "                                  transforms.RandomAutocontrast(p=0.2), transforms.RandomEqualize(p=0.1),\n",
        "                                  transforms.Resize((150,150)),\n",
        "                                  transforms.RandomHorizontalFlip(),\n",
        "                                  transforms.ToTensor(),\n",
        "                                  transforms.Normalize([0.5,0.5,0.5], \n",
        "                                                        [0.5,0.5,0.5])\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W53XPMOlEXai"
      },
      "source": [
        "#Dataloader\n",
        "train_path = \"/content/drive/MyDrive/Colab Notebooks/new_clean_emotions_dataset_v0.1/train/\"\n",
        "test_path = \"/content/drive/MyDrive/Colab Notebooks/new_clean_emotions_dataset_v0.1/train/\"\n",
        "\n",
        "train_loader=DataLoader(\n",
        "    torchvision.datasets.ImageFolder(train_path,transform=transformer),\n",
        "    batch_size=32, shuffle=True\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    torchvision.datasets.ImageFolder(train_path,transform=transformer),\n",
        "    batch_size = 32, shuffle = True\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IL-o-lcqGAi0"
      },
      "source": [
        "root=pathlib.Path(train_path)\n",
        "classes=sorted([j.name.split('/')[-1] for j in root.iterdir()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMwn_3DKGc4K",
        "outputId": "397d3555-d82b-46c8-83a9-a2afef16eb0d"
      },
      "source": [
        "classes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['angry',\n",
              " 'confused',\n",
              " 'crying',\n",
              " 'fear',\n",
              " 'happy',\n",
              " 'puzzled',\n",
              " 'sad',\n",
              " 'scared',\n",
              " 'shy']"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gw947Y-zGhfv"
      },
      "source": [
        "class ConvNet(nn.Module):\n",
        "    def __init__(self,num_classes=9):\n",
        "        super(ConvNet,self).__init__()\n",
        "        \n",
        "        #Output size after convolution filter\n",
        "        #((w-f+2P)/s) +1\n",
        "        \n",
        "        #Input shape= (256,3,150,150)\n",
        "        \n",
        "        self.conv1=nn.Conv2d(in_channels=3,out_channels=12,kernel_size=3,stride=1,padding=1)\n",
        "        #Shape= (256,12,150,150)\n",
        "        self.bn1=nn.BatchNorm2d(num_features=12)\n",
        "        #Shape= (256,12,150,150)\n",
        "        self.relu1=nn.ReLU()\n",
        "        #Shape= (256,12,150,150)\n",
        "        \n",
        "        self.pool=nn.MaxPool2d(kernel_size=2)\n",
        "        #Reduce the image size be factor 2\n",
        "        #Shape= (256,12,75,75)\n",
        "        \n",
        "        \n",
        "        self.conv2=nn.Conv2d(in_channels=12,out_channels=20,kernel_size=3,stride=1,padding=1)\n",
        "        #Shape= (256,20,75,75)\n",
        "        self.relu2=nn.ReLU()\n",
        "        #Shape= (256,20,75,75)\n",
        "        \n",
        "        \n",
        "        \n",
        "        self.conv3=nn.Conv2d(in_channels=20,out_channels=32,kernel_size=3,stride=1,padding=1)\n",
        "        #Shape= (256,32,75,75)\n",
        "        self.bn3=nn.BatchNorm2d(num_features=32)\n",
        "        #Shape= (256,32,75,75)\n",
        "        self.relu3=nn.ReLU()\n",
        "        #Shape= (256,32,75,75)\n",
        "        \n",
        "        \n",
        "        self.fc=nn.Linear(in_features=75 * 75 * 32,out_features=num_classes)\n",
        "        \n",
        "        \n",
        "        \n",
        "        #Feed forwad function\n",
        "        \n",
        "    def forward(self,input):\n",
        "        output=self.conv1(input)\n",
        "        output=self.bn1(output)\n",
        "        output=self.relu1(output)\n",
        "            \n",
        "        output=self.pool(output)\n",
        "            \n",
        "        output=self.conv2(output)\n",
        "        output=self.relu2(output)\n",
        "            \n",
        "        output=self.conv3(output)\n",
        "        output=self.bn3(output)\n",
        "        output=self.relu3(output)\n",
        "            \n",
        "            \n",
        "            #Above output will be in matrix form, with shape (256,32,75,75)\n",
        "            \n",
        "        output=output.view(-1,32*75*75)\n",
        "            \n",
        "            \n",
        "        output=self.fc(output)\n",
        "            \n",
        "        return output\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGHTZpEQJ2mD"
      },
      "source": [
        "net=ConvNet(num_classes=9)\n",
        "model = net"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAn5gsQFKZWB"
      },
      "source": [
        "optimizer = Adam(model.parameters(),lr=0.001,weight_decay=0.0001)\n",
        "loss_function = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Je4WdM15Kouy"
      },
      "source": [
        "num_epochs = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2wOKtZKKsiy",
        "outputId": "a508a9d4-0532-4910-b127-b03c01f880de"
      },
      "source": [
        "train_count = len(glob.glob(train_path+'/**/*.jpg'))\n",
        "test_count = len(glob.glob(test_path+'/**/*.jpg'))\n",
        "print(train_count,test_count)\n",
        "train_dataset = train_count\n",
        "validation_dataset = test_count"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1354 1354\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zz9s70cLrY9r"
      },
      "source": [
        "def Train(epochs,train_loader,val_loader,criterion,optmizer,device, writer):\n",
        "    '''\n",
        "    Training Loop\n",
        "    '''\n",
        "    best_accuracy = 0\n",
        "    print(\"===================================Start Training===================================\")\n",
        "    for e in range(epochs):\n",
        "        train_loss = 0\n",
        "        validation_loss = 0\n",
        "        train_correct = 0\n",
        "        val_correct = 0\n",
        "        # Train the model  #\n",
        "        net.train()\n",
        "        for data, labels in train_loader:\n",
        "            data, labels = data.to(device), labels.to(device)\n",
        "            try:\n",
        "              optmizer.zero_grad()\n",
        "            except Exception:\n",
        "              pass\n",
        "            \n",
        "            outputs = net(data)\n",
        "            \n",
        "            loss = criterion(outputs,labels)\n",
        "            loss.backward()\n",
        "            optmizer.step()\n",
        "            train_loss += loss.item()\n",
        "            _, preds = torch.max(outputs,1)\n",
        "            train_correct += torch.sum(preds == labels.data)\n",
        "\n",
        "        #validate the model#\n",
        "        net.eval()\n",
        "        for data,labels in val_loader:\n",
        "            data, labels = data.to(device), labels.to(device)\n",
        "            val_outputs = net(data)\n",
        "            val_loss = criterion(val_outputs, labels)\n",
        "            validation_loss += val_loss.item()\n",
        "            _, val_preds = torch.max(val_outputs,1)\n",
        "            val_correct += torch.sum(val_preds == labels.data)\n",
        "\n",
        "        train_loss = train_loss/train_dataset\n",
        "        train_acc = train_correct.double() /train_dataset\n",
        "        validation_loss =  validation_loss /validation_dataset\n",
        "        val_acc = val_correct.double() /validation_dataset\n",
        "        print('Epoch: {} \\tTraining Loss: {:.8f} \\tValidation Loss {:.8f} \\tTraining Acuuarcy {:.3f}% \\tValidation Acuuarcy {:.3f}%'\n",
        "                                                           .format(e+1, train_loss,validation_loss,train_acc * 100, val_acc*100))\n",
        "        \n",
        "        if val_acc>best_accuracy:\n",
        "          torch.save(net.state_dict(),'/content/drive/MyDrive/Colab Notebooks/best_checkpoint.model')\n",
        "          best_accuracy=val_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHkH1w9jA7V1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wy9_ET7nrnRf"
      },
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "writer = SummaryWriter('runs/fer2013_experiment_1')\n",
        "criterion= nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6oluw0frlyJ",
        "outputId": "a2fd7dc4-0dd5-4e93-a5a1-5e68fd65fc3c"
      },
      "source": [
        "Train(100,train_loader,test_loader,criterion,optimizer,device,writer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===================================Start Training===================================\n",
            "Epoch: 1 \tTraining Loss: 0.44504537 \tValidation Loss 0.13421032 \tTraining Acuuarcy 66.396% \tValidation Acuuarcy 75.554%\n",
            "Epoch: 2 \tTraining Loss: 0.16755096 \tValidation Loss 0.29400160 \tTraining Acuuarcy 66.248% \tValidation Acuuarcy 24.151%\n",
            "Epoch: 3 \tTraining Loss: 0.16138744 \tValidation Loss 0.21530649 \tTraining Acuuarcy 65.140% \tValidation Acuuarcy 53.840%\n",
            "Epoch: 4 \tTraining Loss: 0.11355878 \tValidation Loss 0.07430257 \tTraining Acuuarcy 67.134% \tValidation Acuuarcy 79.764%\n",
            "Epoch: 5 \tTraining Loss: 0.05365181 \tValidation Loss 0.05758102 \tTraining Acuuarcy 72.526% \tValidation Acuuarcy 80.724%\n",
            "Epoch: 6 \tTraining Loss: 0.04456863 \tValidation Loss 0.03958541 \tTraining Acuuarcy 77.105% \tValidation Acuuarcy 80.724%\n",
            "Epoch: 7 \tTraining Loss: 0.03298505 \tValidation Loss 0.03235780 \tTraining Acuuarcy 80.059% \tValidation Acuuarcy 80.724%\n",
            "Epoch: 8 \tTraining Loss: 0.03027520 \tValidation Loss 0.03014950 \tTraining Acuuarcy 80.576% \tValidation Acuuarcy 80.650%\n",
            "Epoch: 9 \tTraining Loss: 0.03071000 \tValidation Loss 0.03011679 \tTraining Acuuarcy 79.247% \tValidation Acuuarcy 80.724%\n",
            "Epoch: 10 \tTraining Loss: 0.02768620 \tValidation Loss 0.02601444 \tTraining Acuuarcy 80.502% \tValidation Acuuarcy 80.724%\n",
            "Epoch: 11 \tTraining Loss: 0.02861648 \tValidation Loss 0.02558590 \tTraining Acuuarcy 80.576% \tValidation Acuuarcy 80.724%\n",
            "Epoch: 12 \tTraining Loss: 0.02857242 \tValidation Loss 0.02720475 \tTraining Acuuarcy 80.502% \tValidation Acuuarcy 80.724%\n",
            "Epoch: 13 \tTraining Loss: 0.02651230 \tValidation Loss 0.02500827 \tTraining Acuuarcy 80.724% \tValidation Acuuarcy 80.724%\n",
            "Epoch: 14 \tTraining Loss: 0.02575367 \tValidation Loss 0.02664553 \tTraining Acuuarcy 80.724% \tValidation Acuuarcy 80.724%\n",
            "Epoch: 15 \tTraining Loss: 0.02589651 \tValidation Loss 0.02537223 \tTraining Acuuarcy 80.724% \tValidation Acuuarcy 80.724%\n",
            "Epoch: 16 \tTraining Loss: 0.02674039 \tValidation Loss 0.02614956 \tTraining Acuuarcy 80.650% \tValidation Acuuarcy 80.724%\n",
            "Epoch: 17 \tTraining Loss: 0.02612618 \tValidation Loss 0.02516772 \tTraining Acuuarcy 80.724% \tValidation Acuuarcy 80.724%\n"
          ]
        }
      ]
    }
  ]
}